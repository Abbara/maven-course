{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3sQoe2Tg_fb"
      },
      "source": [
        "# ðŸ“š Agentic RAG System\n",
        "This project implements an **intelligent research assistant** that retrieves and synthesizes information using:\n",
        "1. **ArXiv papers** as the primary knowledge source (**RAG approach**)\n",
        "2. **Web search (Tavily API)**\n",
        "3. **LangGraph** for orchestrating the decision-making workflow\n",
        "\n",
        "## ðŸŽ¯ Purpose\n",
        "\n",
        "The system is designed to provide research-backed answers to technical and scientific questions by:\n",
        "- Prioritizing academic and research papers from ArXiv for scientific queries\n",
        "- Falling back to web search for recent developments or non-academic topics\n",
        "- Maintaining conversation context for coherent multi-turn interactions\n",
        "- Ensuring proper attribution and citations in responses\n",
        "\n",
        "## ðŸ”‘ Prerequisites\n",
        "\n",
        "To use this system, you'll need:\n",
        "\n",
        "1. **OpenAI API Key**\n",
        "   - Required for:\n",
        "     - Text embeddings (for semantic search)\n",
        "     - Response generation (GPT-4 Turbo)\n",
        "     - Routing decisions (GPT-4o-mini)\n",
        "   - Get it from: [OpenAI Platform](https://platform.openai.com)\n",
        "\n",
        "2. **Tavily API Key**\n",
        "   - Required for:\n",
        "     - Web search fallback functionality\n",
        "     - Real-time information retrieval\n",
        "     - Academic domain filtering\n",
        "   - Get it from: [Tavily](https://app.tavily.com)\n",
        "\n",
        "3. **Python Environment**\n",
        "   - Python 3.8 or higher\n",
        "   - Required packages (will be installed automatically):\n",
        "     - langchain-community\n",
        "     - langchain_chroma\n",
        "     - langchain_core\n",
        "     - langchain_openai\n",
        "     - langchain_text_splitters\n",
        "     - langgraph\n",
        "     - tavily-python\n",
        "     - openai\n",
        "     - python-dotenv\n",
        "\n",
        "\n",
        "## ðŸ¤– Agentic Workflow Architecture\n",
        "\n",
        "The user workflow is translated into an agentic system through the following components:\n",
        "\n",
        "1. **State Management**\n",
        "   - **Conversation State**: Tracks user queries, system responses, and context\n",
        "   - **Search State**: Maintains information about current search results and sources\n",
        "   - **Decision State**: Stores routing decisions and their rationale\n",
        "\n",
        "2. **Agent Components**\n",
        "   - **Router Agent**: Makes decisions about information sources\n",
        "     - Analyzes query type and context\n",
        "     - Determines optimal search strategy\n",
        "     - Handles fallback mechanisms\n",
        "   \n",
        "   - **Search Agent**: Executes information retrieval\n",
        "     - Manages ArXiv API interactions\n",
        "     - Handles Tavily web search\n",
        "     - Processes and filters results\n",
        "   \n",
        "   - **Synthesis Agent**: Combines and formats information\n",
        "     - Merges multiple sources\n",
        "     - Ensures proper attribution\n",
        "     - Generates coherent responses\n",
        "\n",
        "3. **Feedback Loop**\n",
        "   - System learns from user interactions\n",
        "   - Improves routing decisions over time\n",
        "   - Adapts to user preferences and query patterns\n",
        "\n",
        "## ðŸ“Š Data Requirements and Sources\n",
        "\n",
        "The system requires and manages several types of data:\n",
        "\n",
        "1. **Input Data**\n",
        "   - **User Queries**: Natural language questions and follow-ups\n",
        "   - **Conversation History**: Previous interactions for context\n",
        "   - **User Preferences**: Optional settings for search behavior\n",
        "\n",
        "2. **Knowledge Sources**\n",
        "   - **ArXiv Papers**:\n",
        "     - Source: ArXiv API\n",
        "     - Format: PDF documents\n",
        "     - Update Frequency: Daily\n",
        "     - Coverage: Scientific and technical papers\n",
        "   \n",
        "   - **Web Content**:\n",
        "     - Source: Tavily API\n",
        "     - Format: Web pages and documents\n",
        "     - Update Frequency: Real-time\n",
        "     - Coverage: News, blogs, documentation, etc.\n",
        "\n",
        "3. **Processed Data**\n",
        "   - **Embeddings**: Vector representations of text\n",
        "     - Generated using OpenAI's embedding model\n",
        "     - Stored in vector database\n",
        "   \n",
        "   - **Chunks**: Processed text segments\n",
        "     - Size: Optimized for semantic search\n",
        "     - Metadata: Source, date, relevance score\n",
        "   \n",
        "   - **Citations**: Reference information\n",
        "     - Paper titles, authors, URLs\n",
        "     - Web page sources and dates\n",
        "\n",
        "4. **Output Data**\n",
        "   - **Responses**: Generated answers with citations\n",
        "   - **Search Results**: Ranked and filtered information\n",
        "   - **Conversation Logs**: Interaction history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi4l10mgMCY6"
      },
      "source": [
        "[link text](https://)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "0zyWACuhcfqG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Install required packages\n",
        "! pip install -qU langchain langgraph pypdf chromadb tavily-python openai python-dotenv pyboxen langchain-community langchain_chroma langchain_core langchain_openai langchain_text_splitters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MDJAvAUpcjmN"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os  # Provides functions to interact with the operating system.\n",
        "from pyboxen import boxen  # Used to display stylized boxes in the terminal for better CLI UI.\n",
        "from getpass import getpass  # Allows secure password input without echoing.\n",
        "\n",
        "from typing import TypedDict, List, Dict, Optional, Literal, Union, Annotated, cast  # Used for type annotations and static type checking.\n",
        "from langchain_core.documents import Document  # Represents and structures text data in LangChain.\n",
        "from langchain_core.output_parsers import StrOutputParser  # Parses raw LLM output into usable string format.\n",
        "from langchain_community.document_loaders import PyPDFLoader  # Loads and extracts text from PDF documents.\n",
        "\n",
        "from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter  # Splits text into chunks using markdown headers or character limits.\n",
        "\n",
        "from langchain_chroma import Chroma  # Provides integration with Chroma vector store for embedding storage and retrieval.\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI  # Interfaces with OpenAI for embeddings and chat models.\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate  # Manages prompt templates for chat-based interactions.\n",
        "\n",
        "from langgraph.graph import StateGraph, END  # Helps define state-based logic flows for chat systems.\n",
        "from langchain.memory import ConversationBufferMemory  # Maintains memory of past conversation for context retention.\n",
        "\n",
        "from tavily import TavilyClient  # Interfaces with Tavily for real-time web search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOl5svrxoDkQ"
      },
      "source": [
        "# API Key Submission\n",
        "\n",
        "Please follow the instructions below:\n",
        "\n",
        "1. **Provide the Tavily API Key**\n",
        "2. **Provide the Open API Key**\n",
        "3. **Press Enter** to proceed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y1CrD7yecpRF",
        "outputId": "46b8d2b4-60bb-4e16-dd05-f6415a5ead6a"
      },
      "outputs": [],
      "source": [
        "# Set API keys\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass(\"Enter Tavily API Key (get from https://app.tavily.com): \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVsoCt4BhfRp"
      },
      "source": [
        "## 2. Define State and System Architecture\n",
        "\n",
        "This is important because Agents need context to take decisions and showcase \"Agency\", the state helps us define the information that the agent will require and also capture information through out the whole process.\n",
        "\n",
        "We'll define our system's state and flow using **LangGraph**. The state will track our:\n",
        "- **Input question**\n",
        "- **Retrieved ArXiv results**\n",
        "- **Web search results**\n",
        "- **Final answer**\n",
        "- **Conversation history for context**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9DX0VBugddBN"
      },
      "outputs": [],
      "source": [
        "# Define our system state - this is what passes between nodes in our graph\n",
        "class AgentState(TypedDict):\n",
        "    \"\"\"State definition for our agentic RAG system\"\"\"\n",
        "    question: str  # User's current question\n",
        "    routing_decision: Literal[\"arxiv\", \"web\", \"both\"] # Explicit decision from router\n",
        "    arxiv_results: Optional[List[Document]]  # Results from ArXiv papers (if any)\n",
        "    web_results: Optional[List[Dict]]  # Results from web search (if any)\n",
        "    direct_answer: Optional[str] # Direct answer from Tavily (if any)\n",
        "    answer: str  # Final synthesized answer\n",
        "    conversation_history: str  # Previous Q&A for context\n",
        "    memory: any\n",
        "    next_node: Optional[Literal[\"web_search\", \"synthesize\"]] # Helper key for conditional routing AFTER arxiv retrieval when \"both\" is chosen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym7UTPc4hpli"
      },
      "source": [
        "## 3. Router Node Implementation\n",
        "\n",
        "The **Router Node** is responsible for deciding whether to use **ArXiv papers** or **web search**.\n",
        "- **First**, it tries to use **ArXiv papers** (our local knowledge source).\n",
        "- **Falls back** to **web search** if needed.\n",
        "\n",
        "This demonstrates **strategic decision-making capabilities**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4oSbkgqwdh_R"
      },
      "outputs": [],
      "source": [
        "router_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are a highly specialized research assistant with access to two information sources:\n",
        "1. A collection of ArXiv research papers\n",
        "2. A web search tool\n",
        "\n",
        "Your task is to determine which source(s) would be better to answer the user's question.\n",
        "FIRST try to use ArXiv papers for scientific and academic questions.\n",
        "ONLY use web search if:\n",
        "- The question requires very recent information not likely in research papers\n",
        "- The question is about general knowledge, news, or non-academic topics\n",
        "- The question asks for information beyond what academic papers would contain\n",
        "Choose BOTH if the question requires integrating academic concepts with recent developments, practical applications, or comparing academic views with general information\n",
        "\n",
        "Consider the conversation history for context.\n",
        "\n",
        "Question: {question}\n",
        "Conversation History: {conversation_history}\n",
        "\n",
        "Respond with ONLY ONE of these two options:\n",
        "\"arxiv\" - if the question should be answered using research papers\n",
        "\"web\" - if the question requires web search\n",
        "\"both\" - if both ArXiv and web search are needed\n",
        "\n",
        "Your decision should be a single word only (either \"arxiv\", \"web\" or \"both\"). Do not include any explanation, reasoning, or additional text in your response.\n",
        "\"\"\")\n",
        "\n",
        "def router_node(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    Determines whether to use ArXiv papers, web search or both based on the question.\n",
        "\n",
        "    Args:\n",
        "        state: Current state containing the question and conversation history\n",
        "\n",
        "    Returns:\n",
        "        Dict containing the routing decision.\n",
        "    \"\"\"\n",
        "    # Use a lighter model for routing decisions\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "    # Create a chain that outputs just the decision text\n",
        "    chain = router_prompt | llm | StrOutputParser()\n",
        "\n",
        "    # Invoke the chain with our question and history\n",
        "    # Get the content of the AIMessage object instead of directly calling strip()\n",
        "    decision = chain.invoke({\n",
        "        \"question\": state[\"question\"],\n",
        "        \"conversation_history\": state[\"conversation_history\"]\n",
        "    }).strip().lower()\n",
        "\n",
        "    # Validate decision and set default if needed\n",
        "    if decision not in [\"arxiv\", \"web\", \"both\"]:\n",
        "        print(f\"Router Warning: Unexpected decision '{decision}'. Defaulting to 'web'.\")\n",
        "        decision = \"web\"\n",
        "    \n",
        "    print(boxen(f\"Router raw decision: {decision}\", title=\">>> Router Node\", color=\"blue\", padding=(1, 2)))\n",
        "    \n",
        "    return {\"routing_decision\": decision}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D_WGWpKhz4D"
      },
      "source": [
        "# ArXiv Processor Documentation\n",
        "\n",
        "## Overview\n",
        "The `ArXivProcessor` class is designed to handle processing ArXiv PDFs for retrieval-augmented generation (RAG) systems. It implements document-aware chunking strategies specifically optimized for scientific papers.\n",
        "\n",
        "## Key Features\n",
        "- **Two-step chunking strategy**:\n",
        " 1. Markdown header splitting to preserve document structure\n",
        " 2. Recursive character splitting for handling longer sections effectively\n",
        "- **Confidence-based retrieval** with threshold filtering\n",
        "- **Metadata preservation** from original PDFs\n",
        "\n",
        "## Class Structure\n",
        "\n",
        "### Constructor: `__init__()`\n",
        "Initializes the processor with specialized document chunking strategies:\n",
        "- `MarkdownHeaderTextSplitter` to maintain document section structure\n",
        "- `RecursiveCharacterTextSplitter` for detailed content subdivision\n",
        "\n",
        "### Methods\n",
        "\n",
        "#### `load_and_process(pdf_urls: List[str])`\n",
        "Processes ArXiv PDFs with document-aware chunking:\n",
        "- Loads PDFs from provided URLs\n",
        "- Converts content to markdown-style text with headers\n",
        "- Applies two-stage chunking process\n",
        "- Creates a vector store with OpenAI embeddings\n",
        "\n",
        "#### `retrieve(question: str, confidence_threshold: float = 0.75, k: int = 5)`\n",
        "Retrieves relevant chunks with confidence scoring:\n",
        "- Performs similarity search based on user query\n",
        "- Filters results by confidence threshold\n",
        "- Returns only high-relevance document chunks\n",
        "\n",
        "## Implementation Example\n",
        "The documented code includes a sample implementation that loads and processes two ArXiv papers:\n",
        "- Quantum computing paper: https://arxiv.org/pdf/2305.10343.pdf\n",
        "- LLM research paper: https://arxiv.org/pdf/2303.04137.pdf\n",
        "\n",
        "## Dependencies\n",
        "- `PyPDFLoader` for PDF handling\n",
        "- `MarkdownHeaderTextSplitter` and `RecursiveCharacterTextSplitter` for content chunking\n",
        "- `OpenAIEmbeddings` for vector embeddings\n",
        "- `Chroma` for vector storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "QeTPjOKgdom7",
        "outputId": "56c7257b-75fe-4ba7-fe5b-19c09d6d74b5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36mâ•­â”€\u001b[0m\u001b[36m >>> Initialization \u001b[0m\u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[36mâ”€â•®\u001b[0m                                                         \n",
            "\u001b[36mâ”‚\u001b[0m                                                        \u001b[36mâ”‚\u001b[0m                                                         \n",
            "\u001b[36mâ”‚\u001b[0m   Initializing ArXiv processor with sample papers...   \u001b[36mâ”‚\u001b[0m                                                         \n",
            "\u001b[36mâ”‚\u001b[0m                                                        \u001b[36mâ”‚\u001b[0m                                                         \n",
            "\u001b[36mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                         \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34mâ•­â”€\u001b[0m\u001b[34m >>> PDF Loading \u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34mâ”€â•®\u001b[0m                                                          \n",
            "\u001b[34mâ”‚\u001b[0m                                                       \u001b[34mâ”‚\u001b[0m                                                          \n",
            "\u001b[34mâ”‚\u001b[0m   Loading PDF from https://arxiv.org/pdf/2504.10412   \u001b[34mâ”‚\u001b[0m                                                          \n",
            "\u001b[34mâ”‚\u001b[0m                                                       \u001b[34mâ”‚\u001b[0m                                                          \n",
            "\u001b[34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                          \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mâ•­â”€\u001b[0m\u001b[32m >>> Processing Complete \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m                                                                              \n",
            "\u001b[32mâ”‚\u001b[0m                                   \u001b[32mâ”‚\u001b[0m                                                                              \n",
            "\u001b[32mâ”‚\u001b[0m   Created 35 chunks from 1 PDFs   \u001b[32mâ”‚\u001b[0m                                                                              \n",
            "\u001b[32mâ”‚\u001b[0m                                   \u001b[32mâ”‚\u001b[0m                                                                              \n",
            "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                                              \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mâ•­â”€\u001b[0m\u001b[32m >>> Status \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m                                                                               \n",
            "\u001b[32mâ”‚\u001b[0m                                  \u001b[32mâ”‚\u001b[0m                                                                               \n",
            "\u001b[32mâ”‚\u001b[0m   ArXiv processor initialized!   \u001b[32mâ”‚\u001b[0m                                                                               \n",
            "\u001b[32mâ”‚\u001b[0m                                  \u001b[32mâ”‚\u001b[0m                                                                               \n",
            "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                                               \n",
            "\n"
          ]
        }
      ],
      "source": [
        "class ArXivProcessor:\n",
        "    \"\"\"\n",
        "    Handles processing ArXiv PDFs for retrieval-augmented generation.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the processor with document-aware chunking strategies.\n",
        "\n",
        "        The chunking strategy uses a two-step approach:\n",
        "        1. Markdown header splitting preserves document structure and headers\n",
        "        2. Recursive character splitting handles longer sections effectively\n",
        "        \"\"\"\n",
        "        # Header splitter preserves section structure in scientific papers\n",
        "        self.header_splitter = MarkdownHeaderTextSplitter(\n",
        "            headers_to_split_on=[\n",
        "                (\"#\", \"Section\"),           # Main sections\n",
        "                (\"##\", \"Subsection\"),       # Subsections\n",
        "                (\"###\", \"Subsubsection\")    # Sub-subsections\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Recursive splitter handles nested hierarchies and technical content\n",
        "        # - Chunk size of 1000 balances context vs specificity\n",
        "        # - Overlap of 200 ensures continuity between chunks\n",
        "        # - Separators prioritize natural breaks in scientific text\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=200,\n",
        "            separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
        "        )\n",
        "\n",
        "        # Will be initialized when documents are loaded\n",
        "        self.vector_store = None\n",
        "\n",
        "    def load_and_process(self, pdf_urls: List[str]):\n",
        "        \"\"\"\n",
        "        Process ArXiv PDFs with document-aware chunking\n",
        "\n",
        "        Args:\n",
        "            pdf_urls: List of URLs to ArXiv PDFs\n",
        "        \"\"\"\n",
        "        all_chunks = []\n",
        "\n",
        "        # Process each PDF\n",
        "        for url in pdf_urls:\n",
        "            print(boxen(f\"Loading PDF from {url}\", title=\">>> PDF Loading\", color=\"blue\", padding=1))\n",
        "            loader = PyPDFLoader(url)\n",
        "            pages = loader.load()\n",
        "\n",
        "            # Process each page\n",
        "            for page in pages:\n",
        "                # Convert PDF content to markdown-style text with headers\n",
        "                page_text = f\"# {page.metadata['source']}\\n## Page {page.metadata['page']}\\n{page.page_content}\"\n",
        "\n",
        "                # First split by headers to maintain document structure\n",
        "                header_chunks = self.header_splitter.split_text(page_text)\n",
        "\n",
        "                # Then split large sections into smaller chunks\n",
        "                small_chunks = self.text_splitter.split_documents(header_chunks)\n",
        "\n",
        "                # Add to our collection\n",
        "                all_chunks.extend(small_chunks)\n",
        "\n",
        "        print(boxen(f\"Created {len(all_chunks)} chunks from {len(pdf_urls)} PDFs\", title=\">>> Processing Complete\", color=\"green\", padding=1))\n",
        "\n",
        "        # Create vector store with OpenAI embeddings\n",
        "        self.vector_store = Chroma.from_documents(\n",
        "            documents=all_chunks,\n",
        "            embedding=OpenAIEmbeddings(),\n",
        "            persist_directory=\"./arxiv_db\"\n",
        "        )\n",
        "\n",
        "    def retrieve(self, question: str, confidence_threshold: float = 0.75, k: int = 5):\n",
        "        \"\"\"\n",
        "        Retrieve relevant chunks with confidence scoring\n",
        "\n",
        "        Args:\n",
        "            question: User question to find relevant information for\n",
        "            confidence_threshold: Minimum relevance score (0-1) to include a result\n",
        "            k: Maximum number of results to return\n",
        "\n",
        "        Returns:\n",
        "            List of relevant document chunks that meet the threshold\n",
        "        \"\"\"\n",
        "        if not self.vector_store:\n",
        "            raise ValueError(\"No ArXiv documents loaded. Run load_and_process first.\")\n",
        "\n",
        "        # Perform similarity search with relevance scores\n",
        "        results = self.vector_store.similarity_search_with_relevance_scores(\n",
        "            question, k=k\n",
        "        )\n",
        "\n",
        "        # Filter by confidence threshold\n",
        "        filtered_results = [doc for doc, score in results if score >= confidence_threshold]\n",
        "\n",
        "        print(boxen(f\"Found {len(filtered_results)} relevant chunks above threshold {confidence_threshold}\", title=\">>> ArXivProcessor\", color=\"yellow\", padding=1))\n",
        "\n",
        "        return filtered_results\n",
        "\n",
        "# Load sample ArXiv PDFs\n",
        "print(boxen(\"Initializing ArXiv processor with sample papers...\", title=\">>> Initialization\", color=\"cyan\", padding=1))\n",
        "arxiv_processor = ArXivProcessor()\n",
        "arxiv_processor.load_and_process([\n",
        "    \"https://arxiv.org/pdf/2504.10412\"   # LLM research paper\n",
        "])\n",
        "print(boxen(\"ArXiv processor initialized!\", title=\">>> Status\", color=\"green\", padding=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeaD77BupxMv"
      },
      "source": [
        "# ArXiv Retrieval Node Documentation\n",
        "\n",
        "## Overview\n",
        "The `arxiv_retrieval_node` function serves as a retrieval component in an agent-based system, fetching relevant scientific information from ArXiv papers based on user queries.\n",
        "\n",
        "## Function Signature\n",
        "`arxiv_retrieval_node(state: AgentState) -> dict`\n",
        "\n",
        "## Parameters\n",
        "- `state`: An AgentState object containing the current conversation state, including:\n",
        " - `question`: The user's query to search for in ArXiv papers\n",
        "\n",
        "## Functionality\n",
        "The function:\n",
        "1. Extracts the user's question from the input state\n",
        "2. Calls the `arxiv_processor.retrieve()` method to find relevant document chunks\n",
        "3. Uses a reduced confidence threshold (0.5) compared to the default (0.75) to improve recall\n",
        "4. Returns the retrieved documents for further processing\n",
        "\n",
        "## Return Value\n",
        "Returns a dictionary with:\n",
        "- `arxiv_results`: A list of document chunks from ArXiv papers relevant to the user's question\n",
        "\n",
        "## Integration Notes\n",
        "- This function is designed to be used as a node in an agent workflow\n",
        "- The reduced confidence threshold ensures more potential matches are returned, prioritizing recall over precision\n",
        "- The retrieved documents can be used by subsequent nodes for answering the user's question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7QI0RXSbdvCv"
      },
      "outputs": [],
      "source": [
        "# Ensure arxiv_processor is accessible (defined in previous cells)\n",
        "assert 'arxiv_processor' in globals(), \"arxiv_processor must be initialized first\"\n",
        "\n",
        "def arxiv_retrieval_node(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    Retrieves relevant information from ArXiv papers based on the question.\n",
        "    Determines the next node based on the initial routing decision.\n",
        "    \n",
        "    Args:\n",
        "        state: Current state containing the question and routing decision\n",
        "\n",
        "    Returns:\n",
        "        Updated state with arxiv_results and the next node destination.\n",
        "    \"\"\"      \n",
        "    question = state[\"question\"]\n",
        "    routing_decision = state[\"routing_decision\"]\n",
        "    relevant_docs = []\n",
        "    next_dest = \"synthesize\" # Default next step\n",
        "    \n",
        "    # Retrieve relevant documents from ArXiv\n",
        "    try:\n",
        "        relevant_docs = arxiv_processor.retrieve(\n",
        "            question=question,\n",
        "            confidence_threshold=0.5  # Adjusted threshold for better recall\n",
        "        )\n",
        "        print(boxen(f\"Found {len(relevant_docs)} relevant ArXiv chunks.\", title=\">>> ArXiv Retrieval Node\", color=\"blue\", padding=(1, 2)))\n",
        "    except Exception as e:\n",
        "        print(boxen(f\"Error during ArXiv retrieval: {e}\", title=\">>> ArXiv Retrieval Node\", color=\"red\", padding=(1, 2)))\n",
        "        # Continue even if ArXiv fails, maybe web search will work if \"both\" was chosen\n",
        "\n",
        "    # TODO: Check if we found enough relevant content\n",
        "    \n",
        "    info_message = \"\"\n",
        "    # Decide the next step\n",
        "    if routing_decision == \"both\":\n",
        "        info_message = \"Routing decision was 'both', proceeding to Web Search next.\"\n",
        "        print(boxen(info_message, title=\">>> Routing\", color=\"green\", padding=(1, 2)))\n",
        "        next_dest = \"web_search\"\n",
        "    else: # routing_decision was \"arxiv\"\n",
        "        info_message = \"Routing decision was 'arxiv', proceeding to Synthesize next.\"\n",
        "        print(boxen(info_message, title=\">>> Routing\", color=\"green\", padding=(1, 2)))\n",
        "        next_dest = \"synthesize\"\n",
        "    \n",
        "    return {\"arxiv_results\": relevant_docs, \"next_node\": next_dest}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SqO1XREiD7z"
      },
      "source": [
        "## 5. Web Search Node Implementation\n",
        "\n",
        "The **Web Search Node** uses the **Tavily API** to search the web when **ArXiv papers** don't have the answer.\n",
        "\n",
        "- **Optimizes** the search query\n",
        "- **Filters and processes** results\n",
        "- **Ensures** proper attribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_WsFmnmpd3CI"
      },
      "outputs": [],
      "source": [
        "web_searcher = TavilyClient()\n",
        "\n",
        "def web_search_node(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    Searches the web for information using the Tavily API.\n",
        "    \n",
        "    Args:\n",
        "        state: current state containing the question\n",
        "\n",
        "    Returns:\n",
        "        Updated state with web_results and direct_answer.\n",
        "    \"\"\"    \n",
        "    web_res = None\n",
        "    direct_ans = None\n",
        "    \n",
        "    try:\n",
        "        # Include academic domains to improve search quality\n",
        "        academic_domains = [\"arxiv.org\", \"scholar.google.com\", \"researchgate.net\", \"edu\"]\n",
        "\n",
        "        # Get search results with answer\n",
        "        search_response = web_searcher.search(\n",
        "            query=state[\"question\"],\n",
        "            max_results=5,\n",
        "            include_domains=academic_domains,\n",
        "            search_depth=\"advanced\",  # Use advanced search for better results\n",
        "            include_answer=True  # Request direct answer\n",
        "        )\n",
        "        web_res = search_response.get(\"results\", [])\n",
        "        direct_ans = search_response.get(\"answer\")\n",
        "        info_message = f\"Found {len(web_res)} web results.\" + (f\" Direct answer found.\" if direct_ans else \"\")\n",
        "        print(boxen(info_message, title=\">>> Web Search Node\", color=\"blue\", padding=(1, 2)))\n",
        "    except Exception as e:\n",
        "        print(boxen(f\"Error during Web search: {e}\", title=\">>> Web Search Node\", color=\"red\", padding=(1, 2)))\n",
        "        web_res = [] # Return empty list on error\n",
        "        direct_ans = None\n",
        "\n",
        "    return {\"web_results\": web_res, \"direct_answer\": direct_ans}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYoo-tCciKHn"
      },
      "source": [
        "# Function Documentation: `synthesize_answer_node`\n",
        "\n",
        "## Overview\n",
        "The `synthesize_answer_node` function is a key component in a LangChain-based conversational agent. It is responsible for generating a comprehensive answer based on either scientific research papers (from ArXiv) or web search results (via Tavily). The generated response is contextual, well-structured, and strictly grounded in the retrieved data.\n",
        "\n",
        "---\n",
        "\n",
        "## Purpose\n",
        "To synthesize a high-quality, structured, and citation-backed answer from the information retrieved during the conversational flow â€” either from ArXiv research papers or real-time web search results.\n",
        "\n",
        "---\n",
        "\n",
        "## Inputs\n",
        "\n",
        "- **state (AgentState)**:  \n",
        "  A dictionary representing the current state of the agent, which includes:\n",
        "  - `question`: The user's query.\n",
        "  - `arxiv_results`: A list of research paper excerpts (if available).\n",
        "  - `web_results`: A list of web search results (used when no ArXiv data is present).\n",
        "  - `conversation_history`: Context from previous exchanges to maintain continuity.\n",
        "\n",
        "---\n",
        "\n",
        "## Logic Flow\n",
        "\n",
        "1. **Source Determination**:  \n",
        "   The function first checks whether ArXiv results are available. If so, it uses them; otherwise, it falls back to web search results.\n",
        "\n",
        "2. **Prompt Construction**:  \n",
        "   A custom `prompt_template` is built depending on the data source. Each template includes:\n",
        "   - The original question.\n",
        "   - Retrieved content (formatted accordingly).\n",
        "   - Prior conversation context.\n",
        "   - Explicit instructions to ensure grounded, factual, and well-structured responses.\n",
        "\n",
        "3. **Model Invocation**:  \n",
        "   - Uses `ChatOpenAI` (specifically `gpt-4o-mini`) for advanced reasoning and response generation.\n",
        "   - Combines the prompt and model into a LangChain chain using `ChatPromptTemplate` and `StrOutputParser`.\n",
        "\n",
        "4. **Response Handling**:  \n",
        "   - If web results were used, the function appends a list of source URLs at the end of the response.\n",
        "   - If ArXiv sources were used, inline citations in the format `(Author et al., Page X)` are expected.\n",
        "\n",
        "---\n",
        "\n",
        "## Output\n",
        "\n",
        "- Returns a dictionary with a single key:  \n",
        "  - `answer`: A fully formatted, cited response derived from either research papers or search results.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Characteristics\n",
        "\n",
        "- **Grounded Output**: The model is instructed not to hallucinate or invent facts.\n",
        "- **Citations Included**: Adds credibility and traceability via inline citations or URL references.\n",
        "- **Context-Aware**: Maintains conversation context to provide coherent multi-turn interactions.\n",
        "- **Readable Format**: Uses markdown elements such as headers, bullet points, and bold text for readability.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3h2iGpE9d8VM"
      },
      "outputs": [],
      "source": [
        "def synthesize_answer_node(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    Synthesizes a comprehensive answer from retrieved information (ArXiv, Web, or Both).\n",
        "\n",
        "    Args:\n",
        "        state: Current state containing question and retrieved information\n",
        "\n",
        "    Returns:\n",
        "        Updated state with answer\n",
        "    \"\"\"   \n",
        "    question = state[\"question\"]\n",
        "    arxiv_results = state.get(\"arxiv_results\")\n",
        "    web_results = state.get(\"web_results\")\n",
        "    direct_answer = state.get(\"direct_answer\")\n",
        "    conversation_history = state[\"conversation_history\"]\n",
        "\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1) # Slightly creative for synthesis\n",
        "    final_answer = \"\"\n",
        "    source_type = \"None\"\n",
        "    prompt_template = \"\"\n",
        "    sources_for_prompt = \"\"\n",
        "    displayed_sources = \"\"\n",
        "\n",
        "    # 1. Determine source type and prepare context\n",
        "    if arxiv_results and web_results:\n",
        "        print(boxen(f\"Synthesizing from Both ArXiv and Web Results\", title=\">>> Synthesize Answer Node\", color=\"blue\", padding=(1, 2)))\n",
        "        source_type = \"Combined ArXiv and Web\"\n",
        "        # Format ArXiv results\n",
        "        arxiv_sources = \"\\\\n\\\\n\".join([\n",
        "            f\"--- ArXiv Document: {d.metadata.get('source', 'Unknown')} (Page {d.metadata.get('page', 'N/A')}) ---\\\\n{d.page_content}\"\n",
        "            for d in arxiv_results\n",
        "        ])\n",
        "        # Format Web results\n",
        "        web_sources = \"\\\\n\\\\n\".join([\n",
        "            f\"--- Web Source [{i+1}]: {res.get('title', 'N/A')} ---\\\\n{res.get('content', 'N/A')}\"\n",
        "            for i, res in enumerate(web_results)\n",
        "        ])\n",
        "        \n",
        "        # Format Direct Answer (if any)\n",
        "        direct_answer_context = f\"Tavily suggested direct answer: {direct_answer}\" if direct_answer else \"No direct answer suggested by Tavily.\"\n",
        "\n",
        "        sources_for_prompt = f\"ArXiv Extracts:\\n{arxiv_sources}\\n\\nWeb Search Results:\\n{web_sources}\\n\\n{direct_answer_context}\"\n",
        "        displayed_sources = sources_for_prompt # Show both in logs\n",
        "\n",
        "        prompt_template = \"\"\"\n",
        "        You are a knowledgeable research assistant synthesizing information from both academic papers and web search results.\n",
        "\n",
        "        Task: Answer the user's question comprehensively using ONLY the provided information. Integrate findings, prioritizing ArXiv for core concepts/theory and web search for recent developments, examples, or general context.\n",
        "\n",
        "        Question:\n",
        "        {question}\n",
        "\n",
        "        Conversation History:\n",
        "        {conversation_history}\n",
        "\n",
        "        Information Sources:\n",
        "        {sources}\n",
        "\n",
        "        Instructions:\n",
        "        1. Carefully read and understand all provided ArXiv extracts and web search results.\n",
        "        2. Synthesize a coherent and comprehensive answer addressing the question.\n",
        "        3. Structure the response logically (e.g., introduction, key points from ArXiv, relevant web context/examples, conclusion). Use markdown formatting (headers, lists, bolding) for readability.\n",
        "        4. **Crucially, cite your sources accurately within the text**:\n",
        "            - For ArXiv info: Use (Author et al., Page X) or (Source: Document Source) if author/page unknown.\n",
        "            - For Web info: Use [Web Source 1], [Web Source 2], etc., corresponding to the numbers provided.\n",
        "        5. If the provided information is insufficient or contradictory, state that clearly.\n",
        "        6. DO NOT include information not present in the sources. Base the entire answer strictly on the provided text.\n",
        "        7. Consider the `direct_answer` suggestion from Tavily but verify against the full web results before incorporating its content.\n",
        "\n",
        "        Synthesized Answer:\n",
        "        \"\"\"\n",
        "\n",
        "    elif arxiv_results:\n",
        "        print(boxen(f\"Synthesizing from ArXiv Results\", title=\">>> Synthesize Answer Node\", color=\"blue\", padding=(1, 2)))\n",
        "        source_type = \"ArXiv Papers\"\n",
        "        sources_for_prompt = \"\\\\n\\\\n\".join([\n",
        "            f\"--- Document: {d.metadata.get('source', 'Unknown')} (Page {d.metadata.get('page', 'N/A')}) ---\\\\n{d.page_content}\"\n",
        "            for d in arxiv_results\n",
        "        ])\n",
        "        displayed_sources = sources_for_prompt\n",
        "        prompt_template = \"\"\"\n",
        "        You are a knowledgeable research assistant specializing in mathematical theory and scientific literature analysis.\n",
        "        Your goal is to generate clean, formatted responses to user questions based solely on the provided ArXiv sources.\n",
        "\n",
        "        Question:\n",
        "        {question}\n",
        "\n",
        "        Relevant Extracts from ArXiv Papers:\n",
        "        {sources}\n",
        "\n",
        "        Conversation History:\n",
        "        {conversation_history}\n",
        "\n",
        "        Instructions for Synthesizing the Answer:\n",
        "        1. Read the extracts thoroughly and understand the concepts.\n",
        "        2. Answer the question comprehensively using ONLY the provided context.\n",
        "        3. Organize the response into the following markdown sections (if applicable):\n",
        "              - Summary\n",
        "              - Key Concepts\n",
        "              - Theoretical Results\n",
        "              - Implications / Applications\n",
        "        4. Cite from the paper in the format: (Author et al., Page X). If page number is unknown, write: (Author et al.).\n",
        "        5. Avoid repetition, excessive formal tone, or generic commentary. Be clear and concise.\n",
        "        6. If the provided text lacks enough detail to answer, state it clearly and suggest what additional info is needed.\n",
        "\n",
        "        Now, write a well-structured, markdown-formatted answer to the question and it should be in a readable format as well.\n",
        "        \n",
        "        Your answer:\n",
        "        \"\"\"\n",
        "    elif web_results:\n",
        "        print(boxen(f\"Synthesizing from Web Results\", title=\">>> Synthesize Answer Node\", color=\"blue\", padding=(1, 2)))\n",
        "        source_type = \"Web Search Results\"\n",
        "        web_sources = \"\\\\n\\\\n\".join([\n",
        "            f\"--- Web Source [{i+1}]: {res.get('title', 'N/A')} ---\\\\n{res.get('content', 'N/A')}\"\n",
        "            for i, res in enumerate(web_results)\n",
        "        ])\n",
        "        direct_answer_context = f\"Tavily suggested direct answer: {direct_answer}\" if direct_answer else \"No direct answer suggested by Tavily.\"\n",
        "\n",
        "        sources_for_prompt = f\"Web Search Results:\\n{web_sources}\\n\\n{direct_answer_context}\"\n",
        "        displayed_sources = sources_for_prompt\n",
        "\n",
        "        prompt_template = \"\"\"\n",
        "        You are a knowledgeable research assistant providing accurate information based on web search results.\n",
        "\n",
        "        Question: {question}\n",
        "        \n",
        "        Here are relevant web search results:\n",
        "            {sources}\n",
        "\n",
        "        Conversation History: {conversation_history}\n",
        "\n",
        "        Instructions:\n",
        "        1. Synthesize a comprehensive answer using ONLY the information provided above.\n",
        "        2. Cite sources using [1], [2], etc. corresponding to the source numbers above.\n",
        "        3. Consider the `direct_answer` suggestion from Tavily but verify against the full web results before incorporating its content.\n",
        "        4. If the search results don't contain sufficient information, acknowledge the limitations.\n",
        "        5. DO NOT make up information not present in the sources. \n",
        "        6. Include only facts supported by the sources.\n",
        "        7. Use markdown formatting for readability.\n",
        "\n",
        "        Your answer:\n",
        "        \"\"\"\n",
        "    else:\n",
        "        print(\"No relevant information found to synthesize answer.\")\n",
        "        source_type = \"None\"\n",
        "        final_answer = \"I could not find relevant information from ArXiv or web search to answer your question based on the available documents.\"\n",
        "\n",
        "    # 2. Perform Synthesis (if sources found)\n",
        "    if source_type != \"None\":\n",
        "        # print(f\"\\n\\n=== Retrieved chunks from {source_type} ===\")\n",
        "        # print(displayed_sources)\n",
        "        # print(\"=\"*80)\n",
        "\n",
        "        synthesis_prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "        chain = synthesis_prompt | llm | StrOutputParser()\n",
        "\n",
        "        response = chain.invoke({\n",
        "            \"question\": question,\n",
        "            \"sources\": sources_for_prompt,\n",
        "            \"conversation_history\": conversation_history\n",
        "        })\n",
        "        final_answer = response\n",
        "\n",
        "        # 3. Add URL Citations if Web Results were used\n",
        "        if source_type in [\"Web Search Results\", \"Combined ArXiv and Web\"]:\n",
        "            if web_results: # Ensure web_results is not None/empty\n",
        "                url_citations = \"\\n\\n**Web Sources:**\\n\" + \"\\n\".join([\n",
        "                    f\"[{i+1}] {res.get('url', 'URL not available')}\"\n",
        "                    for i, res in enumerate(web_results)\n",
        "                ])\n",
        "                final_answer += url_citations\n",
        "\n",
        "    # 4. Format Final Output\n",
        "    formatted_output = f\"\"\"## Context\n",
        "**Question:** {question}\n",
        "**Source(s) Used:** {source_type}\n",
        "\n",
        "## Response\n",
        "{final_answer}\n",
        "\"\"\"\n",
        "\n",
        "    return {\"answer\": formatted_output}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePSZSMQBiaMC"
      },
      "source": [
        "## 7. Conversation Memory Node\n",
        "\n",
        "This node **manages conversation history** to provide context for **multi-turn interactions**.\n",
        "\n",
        "- **Stores** previous Q&A\n",
        "- **Updates** the state with the current interaction\n",
        "- **Maintains** a sliding window of relevant history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Pgefbaa_eAfZ"
      },
      "outputs": [],
      "source": [
        "# Initialize conversation memory\n",
        "\n",
        "def update_memory_node(state: AgentState) -> dict:\n",
        "    \"\"\"\n",
        "    Updates the conversation memory with the current Q&A pair.\n",
        "\n",
        "    Args:\n",
        "        state: Current state with question and answer\n",
        "\n",
        "    Returns:\n",
        "        Updated state with new conversation_history\n",
        "    \"\"\"\n",
        "    # Save the current interaction to memory\n",
        "    memory = state['memory']\n",
        "    memory.save_context(\n",
        "        {\"question\": state[\"question\"]},\n",
        "        {\"answer\": state[\"answer\"]}\n",
        "    )\n",
        "\n",
        "    # Return the updated state\n",
        "    return {\"conversation_history\": memory.load_memory_variables({}).get(\"history\", \"\")}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxKEeu64iglN"
      },
      "source": [
        "# Workflow State Graph Setup\n",
        "\n",
        "## Overview\n",
        "This section sets up the **LangGraph state machine** for managing the conversational agentâ€™s workflow. It defines how user queries are processed step-by-step using modular nodes.\n",
        "\n",
        "---\n",
        "\n",
        "## Purpose\n",
        "To create a graph-based control flow that determines how the agent processes input, performs retrieval, synthesizes responses, updates memory, and eventually ends the workflow.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Components\n",
        "\n",
        "### 1. **Workflow Initialization**\n",
        "- A new `StateGraph` is initialized with the `AgentState` type, defining the structure of the workflow.\n",
        "\n",
        "### 2. **Node Definitions**\n",
        "The graph is composed of several functional nodes, each responsible for a specific task:\n",
        "- **router**: Determines whether to fetch data from the web or ArXiv.\n",
        "- **arxiv_retrieval**: Retrieves relevant research papers from ArXiv.\n",
        "- **web_search**: Retrieves web results via Tavily.\n",
        "- **synthesize**: Synthesizes a final answer from the retrieved information.\n",
        "- **update_memory**: Stores the interaction context for future turns.\n",
        "\n",
        "### 3. **Entry Point**\n",
        "- The `router` node is set as the initial entry point for the graph, meaning every workflow starts with routing logic.\n",
        "\n",
        "### 4. **Conditional Routing**\n",
        "- A conditional edge is established from `router` based on the `\"next\"` field in the state:\n",
        "  - If `\"next\"` is `\"web_search\"`, it routes to the `web_search` node.\n",
        "  - If `\"next\"` is `\"arxiv_retrieval\"`, it routes to the `arxiv_retrieval` node.\n",
        "\n",
        "### 5. **Workflow Sequence**\n",
        "The following fixed transitions define the remainder of the workflow:\n",
        "- From either `web_search` or `arxiv_retrieval` â†’ go to `synthesize`\n",
        "- From `synthesize` â†’ go to `update_memory`\n",
        "- From `update_memory` â†’ reach `END` (completion of the flow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BRYbjFhHeEZt"
      },
      "outputs": [],
      "source": [
        "# Create the workflow state graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add all nodes back to the graph\n",
        "workflow.add_node(\"router\", router_node)\n",
        "workflow.add_node(\"arxiv_retrieval\", arxiv_retrieval_node)\n",
        "workflow.add_node(\"web_search\", web_search_node)\n",
        "workflow.add_node(\"synthesize\", synthesize_answer_node)\n",
        "workflow.add_node(\"update_memory\", update_memory_node)\n",
        "\n",
        "# Set entry point\n",
        "workflow.set_entry_point(\"router\")\n",
        "\n",
        "# --- Define Conditional Edges ---\n",
        "\n",
        "# 1. Edges from the Router\n",
        "workflow.add_conditional_edges(\n",
        "    \"router\",\n",
        "    # Function to decide which path to take based on the routing decision\n",
        "    lambda state: state[\"routing_decision\"],\n",
        "    # Mapping: decision -> target node\n",
        "    {\n",
        "        \"arxiv\": \"arxiv_retrieval\",\n",
        "        \"web\": \"web_search\",\n",
        "        \"both\": \"arxiv_retrieval\" # Start with ArXiv if \"both\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# 2. Edges from ArXiv Retrieval\n",
        "workflow.add_conditional_edges(\n",
        "    \"arxiv_retrieval\",\n",
        "    # Function to decide based on the 'next_node' key set within arxiv_retrieval_node\n",
        "    lambda state: state.get(\"next_node\", \"synthesize\"), # Default to synthesize if key missing\n",
        "    {\n",
        "        \"web_search\": \"web_search\",\n",
        "        \"synthesize\": \"synthesize\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# 3. Edge from Web Search (always goes to synthesize)\n",
        "workflow.add_edge(\"web_search\", \"synthesize\")\n",
        "\n",
        "# 4. Edges from Synthesize and Update Memory\n",
        "workflow.add_edge(\"synthesize\", \"update_memory\")\n",
        "workflow.add_edge(\"update_memory\", END)\n",
        "\n",
        "# --- Compile the graph ---\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "3pkhue9nKX3A",
        "outputId": "c7a347b3-d22e-4991-dc31-1b8d283e266b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/me/miniforge3/envs/maven-course/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:623: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
            "  warn(\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Optional: Display the new graph structure\n",
        "from IPython.display import Image, display\n",
        "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m4TP3xSioHc"
      },
      "source": [
        "## 9. Testing the System\n",
        "\n",
        "Let's **test our system** with different types of questions:\n",
        "\n",
        "- **Questions answerable** from ArXiv papers\n",
        "- **Questions requiring** web search\n",
        "- **Follow-up questions** to test memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgjgGd6EJOJO",
        "outputId": "a002fe3e-5370-4674-bfdd-068d568bbf0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clearing memory before initial state creation.\n",
            "Initial State Prepared (Memory Cleared):\n",
            "{'question': None, 'routing_decision': None, 'arxiv_results': None, 'web_results': None, 'direct_answer': None, 'answer': '', 'conversation_history': '', 'memory': ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[]), output_key='answer', input_key='question'), 'next_node': None}\n"
          ]
        }
      ],
      "source": [
        "memory = ConversationBufferMemory(return_messages=False, output_key=\"answer\", input_key=\"question\")\n",
        "\n",
        "# *** CLEAR MEMORY HERE (Optional, but ensures clean start) ***\n",
        "print(\"Clearing memory before initial state creation.\")\n",
        "memory.clear()\n",
        "\n",
        "initial_state = {\n",
        "    \"question\": None,\n",
        "    \"routing_decision\": None, # Initialize new state field\n",
        "    \"arxiv_results\": None,\n",
        "    \"web_results\": None,\n",
        "    \"direct_answer\": None,\n",
        "    \"answer\": \"\",\n",
        "    \"conversation_history\": memory.load_memory_variables({}).get(\"history\", \"\"),\n",
        "    \"memory\": memory,\n",
        "    \"next_node\": None # Initialize helper key\n",
        "}\n",
        "print(\"Initial State Prepared (Memory Cleared):\")\n",
        "print(initial_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "gFoxsXLWeHSv"
      },
      "outputs": [],
      "source": [
        "def ask(app, question: str, state: AgentState):\n",
        "    \"\"\"\n",
        "    Ask a question to the agentic RAG system and print result details.\n",
        "\n",
        "    Args:\n",
        "        app: The compiled LangGraph application.\n",
        "        question: User's question.\n",
        "        state: The current AgentState dictionary (will be updated).\n",
        "\n",
        "    Returns:\n",
        "        The final AgentState dictionary after workflow invocation.\n",
        "    \"\"\"\n",
        "    # Invoke the workflow\n",
        "    state['question'] = question\n",
        "    \n",
        "    # Ensure conversation history is loaded for this turn\n",
        "    state['conversation_history'] = state['memory'].load_memory_variables({}).get(\"history\", \"\")\n",
        "\n",
        "    print(f\"\\n{'='*30} NEW QUERY {'='*30}\")\n",
        "    print(boxen(f\"Processing question: {question}\", title=\">>> Input\", color=\"yellow\", padding=1))\n",
        "\n",
        "    # Invoke the workflow\n",
        "    # Note: The 'state' dictionary is mutable and gets updated by the graph nodes\n",
        "    result = app.invoke(state)\n",
        "    \n",
        "    found_arxiv = result.get(\"arxiv_results\") and len(result[\"arxiv_results\"]) > 0\n",
        "    found_web = result.get(\"web_results\") and len(result[\"web_results\"]) > 0\n",
        "\n",
        "    # # Print ArXiv results count if found\n",
        "    # if found_arxiv:\n",
        "    #     arxiv_count = len(result[\"arxiv_results\"])\n",
        "    #     print(boxen(f\"Found {arxiv_count} ArXiv results\", title=\">>> ArXiv Results\", color=\"magenta\", padding=1))\n",
        "    \n",
        "    # # Print Web results count if found (independent of ArXiv)\n",
        "    # if found_web:\n",
        "    #     web_count = len(result[\"web_results\"])\n",
        "    #     print(boxen(f\"Found {web_count} Web results\", title=\">>> Web Results\", color=\"cyan\", padding=1))\n",
        "    \n",
        "    # Print \"No results\" only if NEITHER was found\n",
        "    if not found_arxiv and not found_web:\n",
        "        print(boxen(\"No relevant information found from any source\", title=\">>> Results\", color=\"red\", padding=1))\n",
        "\n",
        "    # Print the final synthesized answer\n",
        "    # The answer content itself should indicate which sources were used based on the synthesize_node logic\n",
        "    print(boxen(result[\"answer\"], title=\">>> Final Answer\", color=\"green\", padding=(1, 2)))\n",
        "    print(f\"{'='*30} QUERY END {'='*30}\\n\")\n",
        "\n",
        "    # Return the final state which includes the updated memory, answer, etc.\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b0Ps7Nw1exMl",
        "outputId": "5c4f1559-6c79-4882-873a-53d4a177225a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================== NEW QUERY ==============================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mâ•­â”€\u001b[0m\u001b[33m >>> Input \u001b[0m\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[33mâ”€â•®\u001b[0m\n",
            "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
            "\u001b[33mâ”‚\u001b[0m   Processing question: Explain the most recent techniques used in software refactoring. Support it with the     \u001b[33mâ”‚\u001b[0m\n",
            "\u001b[33mâ”‚\u001b[0m   online examples                                                                                               \u001b[33mâ”‚\u001b[0m\n",
            "\u001b[33mâ”‚\u001b[0m                                                                                                                 \u001b[33mâ”‚\u001b[0m\n",
            "\u001b[33mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34mâ•­â”€\u001b[0m\u001b[34m >>> Router Node \u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34mâ”€â•®\u001b[0m                                                                                    \n",
            "\u001b[34mâ”‚\u001b[0m                             \u001b[34mâ”‚\u001b[0m                                                                                    \n",
            "\u001b[34mâ”‚\u001b[0m  Router raw decision: both  \u001b[34mâ”‚\u001b[0m                                                                                    \n",
            "\u001b[34mâ”‚\u001b[0m                             \u001b[34mâ”‚\u001b[0m                                                                                    \n",
            "\u001b[34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                                                    \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mâ•­â”€\u001b[0m\u001b[33m >>> ArXivProcessor \u001b[0m\u001b[33mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[33mâ”€â•®\u001b[0m                                                                \n",
            "\u001b[33mâ”‚\u001b[0m                                                 \u001b[33mâ”‚\u001b[0m                                                                \n",
            "\u001b[33mâ”‚\u001b[0m   Found 5 relevant chunks above threshold 0.5   \u001b[33mâ”‚\u001b[0m                                                                \n",
            "\u001b[33mâ”‚\u001b[0m                                                 \u001b[33mâ”‚\u001b[0m                                                                \n",
            "\u001b[33mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                                \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34mâ•­â”€\u001b[0m\u001b[34m >>> ArXiv Retrieval Node \u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34mâ”€â•®\u001b[0m                                                                               \n",
            "\u001b[34mâ”‚\u001b[0m                                  \u001b[34mâ”‚\u001b[0m                                                                               \n",
            "\u001b[34mâ”‚\u001b[0m  Found 5 relevant ArXiv chunks.  \u001b[34mâ”‚\u001b[0m                                                                               \n",
            "\u001b[34mâ”‚\u001b[0m                                  \u001b[34mâ”‚\u001b[0m                                                                               \n",
            "\u001b[34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                                               \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mâ•­â”€\u001b[0m\u001b[32m >>> Routing \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m                                                  \n",
            "\u001b[32mâ”‚\u001b[0m                                                               \u001b[32mâ”‚\u001b[0m                                                  \n",
            "\u001b[32mâ”‚\u001b[0m  Routing decision was 'both', proceeding to Web Search next.  \u001b[32mâ”‚\u001b[0m                                                  \n",
            "\u001b[32mâ”‚\u001b[0m                                                               \u001b[32mâ”‚\u001b[0m                                                  \n",
            "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                  \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34mâ•­â”€\u001b[0m\u001b[34m >>> Web Search Node \u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34mâ”€â•®\u001b[0m                                                                    \n",
            "\u001b[34mâ”‚\u001b[0m                                             \u001b[34mâ”‚\u001b[0m                                                                    \n",
            "\u001b[34mâ”‚\u001b[0m  Found 5 web results. Direct answer found.  \u001b[34mâ”‚\u001b[0m                                                                    \n",
            "\u001b[34mâ”‚\u001b[0m                                             \u001b[34mâ”‚\u001b[0m                                                                    \n",
            "\u001b[34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                                    \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34mâ•­â”€\u001b[0m\u001b[34m >>> Synthesize Answer Node \u001b[0m\u001b[34mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[34mâ”€â•®\u001b[0m                                                                 \n",
            "\u001b[34mâ”‚\u001b[0m                                                \u001b[34mâ”‚\u001b[0m                                                                 \n",
            "\u001b[34mâ”‚\u001b[0m  Synthesizing from Both ArXiv and Web Results  \u001b[34mâ”‚\u001b[0m                                                                 \n",
            "\u001b[34mâ”‚\u001b[0m                                                \u001b[34mâ”‚\u001b[0m                                                                 \n",
            "\u001b[34mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m                                                                 \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mâ•­â”€\u001b[0m\u001b[32m >>> Final Answer \u001b[0m\u001b[32mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[32mâ”€â•®\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  ## Context                                                                                                     \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  **Question:** Explain the most recent techniques used in software refactoring. Support it with the online      \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  examples                                                                                                       \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  **Source(s) Used:** Combined ArXiv and Web                                                                     \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  ## Response                                                                                                    \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  ## Recent Techniques in Software Refactoring                                                                   \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  Software refactoring is a crucial practice in software engineering aimed at improving code quality without     \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  altering its functionality. Recent advancements in this field have introduced innovative techniques that       \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  leverage modern technologies and methodologies. Below, we explore key techniques from both academic insights   \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  and practical examples.                                                                                        \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  ### Key Techniques from Academic Insights                                                                      \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  1. **AI-Driven Refactoring**: Recent research emphasizes the use of artificial intelligence, particularly      \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  machine learning and deep learning, to automate and enhance the refactoring process. This includes the         \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  application of Graph Neural Networks and large language models (LLMs) to generate and rank refactoring         \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  suggestions, improving maintainability and readability of codebases (Source: ArXiv Document).                  \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  2. **Higher-Level Abstraction Refactoring**: Researchers are increasingly applying refactoring techniques      \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  beyond traditional source code. This includes refactoring at the database level, UML models, and other         \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  high-level abstractions. Techniques are being redefined to suit specific domains, which allows for more        \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  tailored and effective refactoring strategies (Web Source 2).                                                  \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  3. **Extraction Techniques**: Traditional extraction techniques, such as **Extract Method**, **Extract         \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  Class**, and **Extract Variable**, remain popular. These techniques involve breaking down complex code into    \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  smaller, more manageable units, thereby enhancing clarity and reducing complexity (Web Source 3, Web Source    \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  4).                                                                                                            \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  4. **Reinforcement Learning**: There is ongoing exploration into using reinforcement learning for code         \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  refactoring. This approach aims to automate the identification of code smells and suggest improvements,        \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  potentially leading to more efficient refactoring processes (Web Source 5).                                    \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  ### Practical Examples and Context                                                                             \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  1. **Automated Code Generation with LLMs**: A notable example is the EM-Assist plugin for IntelliJ IDEA,       \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  which utilizes LLMs to assist developers in generating refactored code suggestions. This tool employs          \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  few-shot prompting to facilitate move method refactoring and improve code modularization (Web Source 5).       \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  2. **Refactoring in Build Systems**: Techniques such as **Extract Module** and **Pull Up Method** are applied  \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  in build systems to enhance extensibility and maintainability. These methods help in organizing complex build  \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  files into smaller, modular units, making management easier and reducing the likelihood of errors during       \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  updates (Web Source 1).                                                                                        \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  3. **Refactoring for User Interfaces**: In user interface development, refactoring techniques are adapted to   \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  improve UI design while retaining functionality. This involves making structural changes to the UI components  \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  to enhance user experience (Web Source 2).                                                                     \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  ### Conclusion                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  The landscape of software refactoring is evolving with the integration of AI and advanced methodologies.       \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  Techniques such as automated code generation using LLMs, higher-level abstraction refactoring, and             \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  traditional extraction methods are at the forefront of this evolution. As software complexity continues to     \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  grow, these innovative approaches will be vital in maintaining code quality and enhancing developer            \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  productivity.                                                                                                  \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  For further exploration, tools like EM-Assist and various extraction techniques provide practical              \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  applications of these concepts in real-world scenarios.                                                        \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  **Web Sources:**                                                                                               \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  [1] https://arxiv.org/html/2504.01907v1                                                                        \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  [2] https://deepblue.lib.umich.edu/bitstream/handle/2027.42/155872/30YRefactoring.pdf?sequence=4&isAllowed=y   \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  [3] https://densem.edu/HomePages/fulldisplay/464694/RefactoringImprovingTheDesignOfExistingCode.pdf            \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  [4]                                                                                                            \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  https://www.researchgate.net/figure/Top-10-refactoring-techniques-Extraction-techniques-are-quoted-as-a-techn  \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  ique-used-in-5_fig4_341050279                                                                                  \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m  [5] https://arxiv.org/html/2412.18035v1                                                                        \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ”‚\u001b[0m                                                                                                                 \u001b[32mâ”‚\u001b[0m\n",
            "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
            "\n",
            "============================== QUERY END ==============================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test with a question about quantum computing (should use ArXiv)\n",
        "# updated_state = ask(app, \"Explain quantum computing\", initial_state)\n",
        "\n",
        "# Test with a question about drawing (should use web)\n",
        "# updated_state = ask(app, \"Explain how to draw a cat\", initial_state)\n",
        "\n",
        "# Test with a question about latest techniques (should use both ArXiv and web)\n",
        "updated_state = ask(app, \"Explain the most recent techniques used in software refactoring. Support it with the online examples\", initial_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TtHrxeMo1mr"
      },
      "source": [
        "## ðŸŽ“ Conclusion\n",
        "\n",
        "The Agentic RAG System with ArXiv + Web Fallback represents a powerful approach to information retrieval and synthesis, combining the best of both academic and real-time knowledge sources. By intelligently routing queries and maintaining conversation context, it provides:\n",
        "\n",
        "- **Comprehensive Answers**: Leveraging both academic papers and current web information\n",
        "- **Proper Attribution**: Ensuring all sources are properly cited\n",
        "- **Contextual Understanding**: Maintaining conversation history for coherent interactions\n",
        "- **Flexible Knowledge Access**: Adapting to different types of queries and information needs\n",
        "\n",
        "This system is particularly valuable for:\n",
        "- Researchers seeking both theoretical foundations and practical applications\n",
        "- Developers looking for up-to-date technical information\n",
        "- Students and professionals needing comprehensive, well-sourced answers\n",
        "- Anyone requiring a balance between academic rigor and current information\n",
        "\n",
        "The modular architecture and use of LangGraph make it easy to extend and adapt the system for specific use cases or additional knowledge sources."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "maven-course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
